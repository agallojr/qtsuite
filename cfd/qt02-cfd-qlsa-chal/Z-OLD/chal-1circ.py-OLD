"""
wf01 - 

A workflow to create quantum circuits from ORNL's Hele-Shaw solver and run them on IBM's quantum
computers. We'll use lwfm to manage the workflow, track the artifacts, and keep different sets of
dependent libs separated.

1. Read in a TOML file with a list of cases to run
2. For each case, 
    a. Submit a job to generate the quantum circuit
    b. Submit a job to run the quantum circuit
    c. Submit a job to postprocess the results


1. Shots-based study
– Objective: Convergence of the accuracy (fidelity) with the number of shots.
– Try changing the shots parameter and see how the fidelity of the results changes.
– Complete the following tasks to solve the tridiagonal Toeplitz matrix problem.
– Run on simulator only.

Tasks:
(a) Convergence plot of fidelity for solving matrix of size 2 × 2. 
Shot range from 100 to 1,000,000.
Report your deduction of the converged shot value.

(b) Change in fidelity and error due to shots, uncertainty quantification (UQ), with
increase in problem size (matrix size range from 2 × 2 to 32 × 32). Choose shot value
following the convergence study from Task 1(a). Teams can select the UQ metric of their
choice. Report number of times the circuit was run to obtain UQ. 

"""

#pylint: disable=wrong-import-position, invalid-name, superfluous-parens, multiple-statements
#pylint: disable=broad-exception-caught, redefined-outer-name, consider-using-enumerate

import sys
from pathlib import Path
from typing import cast
import pickle
import subprocess

import qiskit    # pylint: disable=unused-import
from qiskit.result import Result as QiskitJobResult
from qiskit_aer.noise import NoiseModel, ReadoutError, depolarizing_error

import numpy as np
import matplotlib.pyplot as plt

from lwfm.base.Workflow import Workflow
from lwfm.base.JobDefn import JobDefn
from lwfm.midware.LwfManager import lwfManager, logger
from lwfm.base.JobStatus import JobStatus
from lwfm.base.JobContext import JobContext

from qtlib import get_cases_args

def add_custom_noise():
    """
    Add custom noise to a sim backend.
    """
    noise_model = NoiseModel()
    error_1q = depolarizing_error(0.0000001, 1)  # 0.00001% - minimal but measurable
    noise_model.add_all_qubit_quantum_error(error_1q,
        ['h', 'x', 'y', 'z', 'rx', 'ry', 'rz'])

    error_2q = depolarizing_error(0.0000005, 2)  # 0.00005% - minimal but measurable
    noise_model.add_all_qubit_quantum_error(error_2q, ['cx', 'cy', 'cz'])

    # Keep readout errors for any sampling-based measurements
    readout_error = ReadoutError([[0.995, 0.005], [0.01, 0.99]])
    noise_model.add_all_qubit_readout_error(readout_error)

    return noise_model


def plot_qlsa_results(
    classical_solution: np.ndarray,
    quantum_results: list,
    case_labels: list[str],
    shot_counts: list[int],
    output_path: str,
    show_plot: bool = False) -> str:
    """
    Plot fidelity vs shots for QLSA convergence study.
    
    Parameters
    ----------
    classical_solution : np.ndarray
        Classical solution vector
    quantum_results : list
        List of quantum solution vectors (one per case)
    case_labels : list[str]
        Labels for each quantum case (e.g., shot counts)
    shot_counts : list[int]
        Number of shots for each case
    output_path : str
        Path to save the plot
    show_plot : bool
        Whether to open the plot after saving
        
    Returns
    -------
    str
        Path to the saved plot file
    """

    # Calculate fidelity for each quantum result
    fidelities = []
    for i, qresult in enumerate(quantum_results):
        print(f"\n=== Fidelity calculation for case {i+1} ===")
        print(f"Classical solution: {classical_solution}")
        print(f"Quantum result: {qresult}")

        # For quantum linear systems, fidelity is often measured as the squared overlap
        # between normalized classical and quantum solution vectors
        classical_norm = np.linalg.norm(classical_solution)
        quantum_norm = np.linalg.norm(qresult)

        print(f"Classical norm: {classical_norm:.6f}")
        print(f"Quantum norm: {quantum_norm:.6f}")

        if classical_norm > 0 and quantum_norm > 0:
            # Normalize both vectors
            classical_normalized = classical_solution / classical_norm
            quantum_normalized = qresult / quantum_norm

            print(f"Classical normalized: {classical_normalized}")
            print(f"Quantum normalized: {quantum_normalized}")

            # Fidelity = |<classical_normalized|quantum_normalized>|^2
            inner_product = np.abs(np.dot(classical_normalized, quantum_normalized))
            fidelity = inner_product ** 2
            print(f"Inner product: {inner_product:.6f}")
            print(f"Fidelity: {fidelity:.6f}")
        else:
            fidelity = 0.0
            print("Zero norm detected, fidelity = 0.0")

        fidelities.append(fidelity)

    # Create figure with single plot
    _, ax = plt.subplots(1, 1, figsize=(10, 6))

    # Plot fidelity vs shots
    ax.semilogx(shot_counts, fidelities, 'o-', linewidth=0, markersize=8,
                color='#2E8B57', markerfacecolor='#FF6B6B', markeredgecolor='#2E8B57')

    # Add horizontal line at fidelity = 1 (perfect match)
    ax.axhline(y=1.0, color='#BF5700', linestyle='--', alpha=0.7,
               label='Perfect Fidelity')

    # Add fidelity values and case labels as text annotations
    for i, (shots, fidelity, label) in enumerate(zip(shot_counts, fidelities, case_labels)):
        ax.annotate(label,
                   (shots, fidelity),
                   textcoords="offset points",
                   xytext=(-12, 10),
                   ha='center', fontsize=8,
                   bbox=dict(boxstyle='round,pad=0.2', fc='white', alpha=0.7))

    ax.set_xlabel('Number of Shots', fontsize=12)
    ax.set_ylabel('Fidelity', fontsize=12)
    ax.set_title('QLSA Fidelity Convergence', fontsize=12)
    ax.grid(True, alpha=0.3)
    ax.legend(
        loc='upper center',
        bbox_to_anchor=(0.5, -0.15),
        ncol=2,
        fancybox=True,
        shadow=True)

    # Set y-axis limits to focus on high fidelity range (0.2-1.0)
    min_fidelity = min(fidelities)
    y_min = min_fidelity - 0.02    # slightly below min fidelity
    ax.set_ylim(y_min, 1.02)       # slightly above max fidelity

    # Format x-axis to show shot counts clearly
    ax.set_xlim(min(shot_counts) * 0.8, max(shot_counts) * 1.2)

    plt.tight_layout()
    plt.savefig(output_path, bbox_inches='tight', dpi=300)

    if show_plot:
        subprocess.Popen(['open', output_path])  # macOS

    return output_path

if __name__ == '__main__':

    # ******************************************************************************
    # get the arguments for the cases in this workflow from the TOML file

    casesArgs = get_cases_args()
    globalArgs = casesArgs["global"]

    # make an lwfm workflow to bundle all these cases
    wf = Workflow("winter challenge 1", "ornl winter challenge - part 1", globalArgs)
    if (wf := lwfManager.putWorkflow(wf)) is None: sys.exit(1)
    logger.info(f"Registered workflow {wf.getWorkflowId()}")

    # modify the output directory name to include the workflow ID
    globalArgs["savedir"] = globalArgs["savedir"] + "/" + str(wf.getWorkflowId())
    keepSaveDir = globalArgs["savedir"]   # will be altered per case, so keep a copy of the root

    # warm up lwfm sandboxes we use by updating their respective dependencies
    if globalArgs.get("warmup_sites", True):
        lwfManager.updateSite()                                     # this projct folder ("./.venv")
        lwfManager.updateSite(globalArgs["preprocess_site"])        # makes the circuits
        lwfManager.updateSite(globalArgs["exec_site"])              # runs the circuits

    preprocess_site = lwfManager.getSite(globalArgs["preprocess_site"])
    exec_site = lwfManager.getSite(globalArgs["exec_site"])


    # ******************************************************************************

    # keep track of the results for each case
    caseResults: list[QiskitJobResult] = []
    quantum_solutions = []

    # we know this workflow will run the same circuit multiple times, so we'll test if
    # this is the first case and do all the preprocessing just once
    firstCase = True
    matrix = None       # the A in A x = b
    vector = None       # the b in A x = b


    # 0. populate ORNL code property file template for the case
    # 1. circuit generation
    # 2. circuit execution
    # 3. post processing
    # we'll also do postprocessing for the workflow as a whole at the end

    # for each case in the workflow toml
    for caseId, caseArgs in ((k, v) for k, v in casesArgs.items() if k != "global"):
        # get the args for this case and merge in the global args
        globalArgs["savedir"] = keepSaveDir + "/" + caseId
        caseArgs.update(globalArgs)

        # we'll put all the artifacts for this case in its own subdir of the workflow root
        caseOutDir = Path(globalArgs["savedir"])
        caseOutDir.mkdir(parents=True, exist_ok=True)

        if firstCase:
            # **************************************************************************
            # 0. populate ORNL code property file template for the case

            # take the templatized ORNL input_vars.yaml, fill it in with the case args, save it
            with open("./input_vars.yaml", "r", encoding="utf-8") as f:
                input_vars = f.read()
            for key, value in caseArgs.items():
                input_vars = input_vars.replace("$" + key, str(value))
            out_dir = caseOutDir
            out_path = out_dir.joinpath(f"input_vars_{caseId}.yaml")
            circuit_qpy_path = \
                out_dir.joinpath(f"{caseArgs['case']}_circ_nqmatrix{caseArgs['NQ_MATRIX']}.qpy")
            # If the ORNL code expects the case to be the second YAML document
            # (doc index 1) for 'hele-shaw', so we hack it up by writing a two-document YAML file
            # where the first document is a minimal placeholder and the second is the
            # actual filled template. Other cases remain single-document files.
            if caseArgs.get('case') == 'hele-shaw':
                placeholder = "placeholder: true\ncase_name: placeholder\n"
                with open(out_path, "w", encoding="utf-8") as f:
                    f.write(placeholder)
                    f.write("---\n")
                    f.write(input_vars)
            else:
                with open(out_path, "w", encoding="utf-8") as f:
                    f.write(input_vars)
            # associate the input_vars file with the workflow
            lwfManager.notatePut(out_path.as_posix(),
                JobContext().initialize("template", wf.getWorkflowId()), {"case": caseId})


            # **************************************************************************
            # 1. circuit generation/preprocessing

            # in circuit generation, we need to discretize the governing Hele-Shaw equations into
            # their Ax=B linear form. the matrix A represents the equations, and vector b
            # the boundary conditions. all of this is done for us by the circuit_HHL.py script given
            # parameters found in a casefile - in goes things like grid resolution, #qubits, etc.
            # and out comes a quantum circuit in a Qiskit-portable QPY format.

            # run the ORNL code to take the CFD casefile and generate the circuit (.qpy), save its
            # extra data (.pkl). we will not let it transpile the circuit, as we will do that
            # ourselves in the execution step.

            preprocess_status = preprocess_site.getRunDriver().submit(
                JobDefn(f"python {caseArgs['circuit_hhl_path']}", JobDefn.ENTRY_TYPE_SHELL,
                    ["-case", caseArgs['case'], "-casefile", str(out_path), "--savedata",
                        "--no-transpile"]),
                    JobContext().initialize("preproc",
                        wf.getWorkflowId(), preprocess_site.getSiteName()))
            if (preprocess_status is None):
                logger.error(f"Preprocess job submission failed {caseId}")
                continue  # to next case
            preprocess_status = lwfManager.wait(preprocess_status.getJobId())
            if (preprocess_status is None) or (preprocess_status.getStatus() != JobStatus.COMPLETE):
                logger.error(f"Preprocess job failed {caseId}")
                continue  # to next case
            lwfManager.notateGet(out_path.as_posix(), preprocess_status.getJobContext(),
                {"case": caseId})

            # locate the QPY file produced by the preprocess step. The wciscc2025
            # code composes the filename based on the actual matrix size (may pad
            # up to a power of two), so don't assume NQ_MATRIX from the TOML.
            # pick the most recently modified QPY in case multiple exist
            qpy_candidates = list(caseOutDir.glob(f"{caseArgs['case']}_circ_nqmatrix*.qpy"))
            if not qpy_candidates:
                logger.error(f"No generated .qpy found for {caseId} in {caseOutDir}")
                continue  # to next case
            circuit_qpy_path = max(qpy_candidates, key=lambda p: p.stat().st_mtime)
            lwfManager.notatePut(circuit_qpy_path.as_posix(), preprocess_status.getJobContext(),
                {"case": caseId})
            # pick the most recently modified PKL in case multiple exist
            pkl_candidates = list(caseOutDir.glob(f"{caseArgs['case']}_circ_nqmatrix*.pkl"))
            if not pkl_candidates:
                logger.error(f"No generated .qpy found for {caseId} in {caseOutDir}")
                continue  # to next case
            circuit_pkl_path = max(pkl_candidates, key=lambda p: p.stat().st_mtime)
            lwfManager.notatePut(circuit_pkl_path.as_posix(), preprocess_status.getJobContext(),
                {"case": caseId})

            # get the matrix and vector from the PKL
            with open(circuit_pkl_path, "rb") as f:
                pkl_data = pickle.load(f)
                matrix = pkl_data["matrix"]
                vector = pkl_data["vector"]

            # based on the size of the matrix, we can infer the number of qubits
            n_qubits_matrix = int(np.log2(matrix.shape[0]))
            logger.info(f"# qubits = {n_qubits_matrix}")
            logger.info(f"# rows = {matrix.shape[0]}")
            logger.info(f"# cols = {matrix.shape[1]}")
            logger.info(f"# nonzeros = {np.count_nonzero(matrix)}")
            logger.info(f"# nonzeros / size = {np.count_nonzero(matrix) / matrix.size}")

            # Calculate classical solution once for all cases to use as reference
            classical_solution_vector = np.linalg.solve(matrix, vector/np.linalg.norm(vector))
            classical_euclidean_norm = float(np.linalg.norm(classical_solution_vector))
            logger.info(f"Classical solution vector: {classical_solution_vector}")
            logger.info(f"Classical euclidean norm: {classical_euclidean_norm}")

        # **************************************************************************
        # the rest of this loop is run per case
        # **************************************************************************

        firstCase = False

        # **************************************************************************
        # 2. circuit execution step - use a venv site for the target backend

        computeType = caseArgs["qc_backend"]    # simulators or real machines

        runArgs = {
            "shots": caseArgs["qc_shots"],      # how many shot/samples per run
            "measure_all": True,                # the circuit won't have a measurement yet, add it
            "optimization_level": 0,            # how much 0 none, 3 max, transpile optimization
        }

        if "_sim_aer" in computeType and caseArgs["sim_custom_noise"]:
            custom_noise_model = add_custom_noise()
            runArgs["noise_model"] = lwfManager.serialize(custom_noise_model)

        exec_status = exec_site.getRunDriver().submit(
            JobDefn(circuit_qpy_path.as_posix(),                # run this circuit
                JobDefn.ENTRY_TYPE_STRING, {"format": ".qpy"}), # stored in this format
            JobContext().initialize(f"{caseArgs['qc_shots']}",  # in its own job context
                        wf.getWorkflowId(), exec_site.getSiteName()),
            computeType,                                        # on this backed
            runArgs)                                            # with these args
        if exec_status is None:
            logger.error(f"Circuit execution job submission failed {caseId}")
            continue    # to next case
        exec_status = lwfManager.wait(exec_status.getJobId())
        if (exec_status is None) or (exec_status.getStatus() != JobStatus.COMPLETE):
            logger.error(f"Circuit execution job failed {caseId}")
            continue    # to next case
        lwfManager.notateGet(circuit_qpy_path.as_posix(), exec_status.getJobContext(),
            {"case": caseId})


        # **************************************************************************
        # 3. per-case postprocess step

        result = cast(QiskitJobResult, lwfManager.deserialize(exec_status.getNativeInfo()))

        # Extract solution from measurement counts
        # Handle different result types from IBM runtime vs simulators
        if hasattr(result, 'data') and callable(result.data):
            # QiskitJobResult from simulators
            counts = result.data()["counts"] if "counts" in result.data() else result.get_counts()
            theData = result.data()
        else:
            # PrimitiveResult from IBM runtime
            if hasattr(result, 'get_counts'):
                counts = result.get_counts()
                theData = result
            else:
                # Handle BitArray from IBM runtime
                bit_array = result[0].data.meas
                counts = bit_array.get_counts()  # Convert BitArray to counts dictionary
                theData = result
        logger.info(f"Case {caseId} - Measurement counts: {counts}")

        # For HHL with measurements, extract solution from middle register (based on HHL structure)
        # Solution qubits are located in the middle of the register, not first or last
        total_shots = sum(counts.values())
        logger.info(f"Case {caseId} - Total shots: {total_shots}")
        n_solution = 2 ** n_qubits_matrix  # Matrix size = 2^n_qubits_matrix
        quantum_solution = np.zeros(n_solution)

        # HHL solution extraction based on observed measurement bitstring pattern
        # Extract solution from the last n_qubits_matrix bits of each measurement as the
        # HHL circuit places the solution in some, and uses others as ancillas.

        for bitstring, count in counts.items():
            # Convert bitstring to state index (handle both hex and binary formats)
            # Qiskit is going to return the bitstring in hex format
            if bitstring.startswith('0x'):
                state_index = int(bitstring, 16)  # Hexadecimal format
            else:
                state_index = int(bitstring, 2)   # Binary format

            # Extract solution register bits (last n_qubits_matrix bits)
            solution_bits = state_index & ((1 << n_qubits_matrix) - 1)

            if solution_bits < n_solution:
                quantum_solution[solution_bits] += count / total_shots

        # Filter near-zero components (like HHL reference implementation)
        quantum_solution[np.abs(quantum_solution) < 1e-10] = 0

        logger.info(f"Case {caseId} - Raw quantum solution: {quantum_solution}")

        # Normalize and scale to match classical solution
        if np.linalg.norm(quantum_solution) > 0:
            quantum_solution = quantum_solution / np.linalg.norm(quantum_solution) \
                * classical_euclidean_norm
            solvec_hhl = quantum_solution
        else:
            logger.warning("Zero norm quantum solution from measurements")
            solvec_hhl = np.zeros(n_solution)

        logger.info(f"Case {caseId}, Solution vector: {solvec_hhl}")

        # write result to file in case directory
        result_path = caseOutDir / "results.out"
        with open(result_path, "w", encoding="utf-8") as f:
            f.write(str(result))
            f.write(str(theData))
            f.write(str(solvec_hhl))
        lwfManager.notatePut(result_path.as_posix(), exec_status.getJobContext(), {"case": caseId})

        # save the job info and solution for postprocessing
        caseResults.append(result)
        quantum_solutions.append(solvec_hhl)

        # **************************************************************************
        # end of case loop
        # **************************************************************************


    # ******************************************************************************
    # workflow post-process

    logger.info("End of case iterations - now post-processing workflow")

    # Classical solution already calculated during first case processing

    # Prepare data for plotting using already-extracted solutions
    case_labels = []
    shot_counts = []

    # Get case info for each result
    for i, result in enumerate(caseResults):
        case_id = list(casesArgs.keys())[i+1]  # +1 to skip 'global'
        shots = casesArgs[case_id]['qc_shots']
        shot_counts.append(shots)
        case_labels.append(f"{shots} shots")

    # now with the pre-chewed per-result data, generate the fidelity convergence plot
    if quantum_solutions:
        plot_output_path = globalArgs["savedir"] + "/qlsa_fidelity_convergence.png"
        case_labels = \
         [f"{case_id}"
            for case_id, case_params in casesArgs.items() if case_id != 'global']
        plot_path = plot_qlsa_results(
            classical_solution=classical_solution_vector,
            quantum_results=quantum_solutions,
            case_labels=case_labels,
            shot_counts=shot_counts,
            output_path=plot_output_path,
            show_plot=False
        )
        logger.info(f"Generated fidelity convergence plot: {plot_path}")
        lwfManager.notatePut(plot_path, exec_status.getJobContext(), {})

    # end of workflow
    logger.info(f"End of workflow {wf.getWorkflowId()}")
